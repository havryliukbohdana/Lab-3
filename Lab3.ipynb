{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlO8wJH6Iq4+xb/fG1WkSG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Встановлення необхідних бібліотек\n",
        "!pip install transformers datasets accelerate evaluate sentencepiece -q"
      ],
      "metadata": {
        "id": "56LUuGZ-SyoP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m_D71T2cRRVp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DefaultDataCollator,\n",
        "    pipeline\n",
        ")\n",
        "import evaluate\n",
        "import collections\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Фіксація seed для відтворюваності\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfVIZVC9S2Ae",
        "outputId": "39af4cb8-dcfa-4e57-c322-ce11f0b3e955"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Завантаження датасету\n",
        "raw_datasets = load_dataset(\"squad_v2\")\n",
        "\n",
        "# Для швидкості беремо частину даних\n",
        "train_subset = raw_datasets[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "val_subset = raw_datasets[\"validation\"].select(range(500))\n",
        "\n",
        "print(\"Приклад даних:\", train_subset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbWYW3RWS_Rb",
        "outputId": "bd19612a-e5a3-4894-8496-a89e17fb3cb2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Приклад даних: {'id': '56e0f3907aa994140058e80a', 'title': 'Canon_law', 'context': 'The Roman Catholic Church canon law also includes the main five rites (groups) of churches which are in full union with the Roman Catholic Church and the Supreme Pontiff:', 'question': 'What term characterizes the intersection of the rites with the Roman Catholic Church?', 'answers': {'text': ['full union'], 'answer_start': [104]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція препроцесингу\n",
        "def preprocess_function(examples, tokenizer):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\", # Обрізаємо контекст, якщо він задовгий, а не питання\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        # Якщо відповіді немає (SQuAD v2 unanswerable)\n",
        "        if len(answer[\"answer_start\"]) == 0:\n",
        "            start_positions.append(0) # CLS token index\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Знаходимо токени старту і кінця\n",
        "            start_char = answer[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answer[\"text\"][0])\n",
        "            sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "            # Знаходимо межі контексту\n",
        "            idx = 0\n",
        "            while sequence_ids[idx] != 1:\n",
        "                idx += 1\n",
        "            context_start = idx\n",
        "            while sequence_ids[idx] == 1:\n",
        "                idx += 1\n",
        "            context_end = idx - 1\n",
        "\n",
        "            # Якщо відповідь виходить за межі обрізаного контексту -> CLS\n",
        "            if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "                start_positions.append(0)\n",
        "                end_positions.append(0)\n",
        "            else:\n",
        "                # Рухаємось до початку відповіді\n",
        "                idx = context_start\n",
        "                while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                    idx += 1\n",
        "                start_positions.append(idx - 1)\n",
        "\n",
        "                # Рухаємось до кінця відповіді\n",
        "                idx = context_end\n",
        "                while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                    idx -= 1\n",
        "                end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "zKSA7qJBS4-V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_table = []\n",
        "\n",
        "def run_experiment(model_checkpoint):\n",
        "    print(f\"\\nProcessing: {model_checkpoint}\")\n",
        "\n",
        "    # 1. Токенізація\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "    # Виправляємо проблему з DeBERTa tokenizer (іноді потрібен add_prefix_space)\n",
        "    if \"deberta\" in model_checkpoint:\n",
        "         tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
        "\n",
        "    # Видаляємо старі колонки, щоб уникнути конфліктів\n",
        "    tokenized_train = train_subset.map(\n",
        "        lambda x: preprocess_function(x, tokenizer),\n",
        "        batched=True,\n",
        "        remove_columns=raw_datasets[\"train\"].column_names\n",
        "    )\n",
        "    tokenized_val = val_subset.map(\n",
        "        lambda x: preprocess_function(x, tokenizer),\n",
        "        batched=True,\n",
        "        remove_columns=raw_datasets[\"validation\"].column_names\n",
        "    )\n",
        "\n",
        "    # 2. Модель\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "\n",
        "    # Підрахунок параметрів\n",
        "    model_params = model.num_parameters() / 1e6\n",
        "    print(f\"Parameters: {model_params:.2f}M\")\n",
        "\n",
        "    # 3. Налаштування тренування\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"{model_checkpoint}-finetuned-squad\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=2,\n",
        "        weight_decay=0.01,\n",
        "        save_strategy=\"no\",\n",
        "        fp16=True,\n",
        "        push_to_hub=False,\n",
        "    )\n",
        "\n",
        "    data_collator = DefaultDataCollator()\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_val,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    # 4. Навчання + Замір часу\n",
        "    start_time = time.time()\n",
        "    train_output = trainer.train()\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    # 5. Оцінка\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    val_loss = eval_metrics[\"eval_loss\"]\n",
        "\n",
        "    # Розмір моделі на диску (приблизний)\n",
        "    model_size_mb = model_params * 4\n",
        "\n",
        "    # Збереження результатів\n",
        "    results_table.append({\n",
        "        \"Модель\": model_checkpoint,\n",
        "        \"Параметри (M)\": round(model_params, 2),\n",
        "        \"Час навчання (сек)\": round(training_time, 2),\n",
        "        \"Validation Loss\": round(val_loss, 4),\n",
        "        \"Розмір ваг (MB)\": round(model_size_mb, 2)\n",
        "    })\n",
        "\n",
        "    return trainer, tokenizer"
      ],
      "metadata": {
        "id": "4n80ryhtTGDs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API: 31e61c678bbd9ec126928439dcfdf0c39398986e"
      ],
      "metadata": {
        "id": "S0YWvLqid8oT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск експериментів\n",
        "\n",
        "# Модель 1: RoBERTa Base\n",
        "trainer_roberta, tokenizer_roberta = run_experiment(\"roberta-base\")\n",
        "\n",
        "# Модель 2: DeBERTa v3 Base (сучасніша, зазвичай краща якість)\n",
        "trainer_deberta, tokenizer_deberta = run_experiment(\"microsoft/deberta-v3-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "hIJ8c4ljTLxb",
        "outputId": "f18f5da2-e42a-4d50-d63d-81150acf6b9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: roberta-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 124.06M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2859249014.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhavryliuk-bohdana\u001b[0m (\u001b[33mhavryliuk-bohdana-igor-sikorsky-kyiv-polytechnic-institute\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251215_201255-f7ehbtek</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/havryliuk-bohdana-igor-sikorsky-kyiv-polytechnic-institute/huggingface/runs/f7ehbtek' target=\"_blank\">efficient-sea-2</a></strong> to <a href='https://wandb.ai/havryliuk-bohdana-igor-sikorsky-kyiv-polytechnic-institute/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/havryliuk-bohdana-igor-sikorsky-kyiv-polytechnic-institute/huggingface' target=\"_blank\">https://wandb.ai/havryliuk-bohdana-igor-sikorsky-kyiv-polytechnic-institute/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/havryliuk-bohdana-igor-sikorsky-kyiv-polytechnic-institute/huggingface/runs/f7ehbtek' target=\"_blank\">https://wandb.ai/havryliuk-bohdana-igor-sikorsky-kyiv-polytechnic-institute/huggingface/runs/f7ehbtek</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 01:31, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.762801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.681704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: microsoft/deberta-v3-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaV2ForQuestionAnswering were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2859249014.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 183.83M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 02:44, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.349463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.160072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Вивід таблиці\n",
        "df_results = pd.DataFrame(results_table)\n",
        "print(\"\\nПорівняння моделей\")\n",
        "display(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "kh3xqFrHTMhY",
        "outputId": "5c4001c6-e92c-4099-bd7b-211d3d402bfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Порівняння моделей\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      Модель  Параметри (M)  Час навчання (сек)  \\\n",
              "0               roberta-base         124.06               99.72   \n",
              "1  microsoft/deberta-v3-base         183.83              167.59   \n",
              "\n",
              "   Validation Loss  Розмір ваг (MB)  \n",
              "0           1.6817           496.23  \n",
              "1           2.1601           735.33  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47520586-aad5-40f2-95ec-1d88915b216b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Модель</th>\n",
              "      <th>Параметри (M)</th>\n",
              "      <th>Час навчання (сек)</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Розмір ваг (MB)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>roberta-base</td>\n",
              "      <td>124.06</td>\n",
              "      <td>99.72</td>\n",
              "      <td>1.6817</td>\n",
              "      <td>496.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>microsoft/deberta-v3-base</td>\n",
              "      <td>183.83</td>\n",
              "      <td>167.59</td>\n",
              "      <td>2.1601</td>\n",
              "      <td>735.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47520586-aad5-40f2-95ec-1d88915b216b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47520586-aad5-40f2-95ec-1d88915b216b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47520586-aad5-40f2-95ec-1d88915b216b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c9b59582-e65f-480f-ae18-84a707c9478f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9b59582-e65f-480f-ae18-84a707c9478f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c9b59582-e65f-480f-ae18-84a707c9478f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"\\u041c\\u043e\\u0434\\u0435\\u043b\\u044c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"microsoft/deberta-v3-base\",\n          \"roberta-base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u0438 (M)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42.26377231151995,\n        \"min\": 124.06,\n        \"max\": 183.83,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          183.83,\n          124.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0427\\u0430\\u0441 \\u043d\\u0430\\u0432\\u0447\\u0430\\u043d\\u043d\\u044f (\\u0441\\u0435\\u043a)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.991337239130985,\n        \"min\": 99.72,\n        \"max\": 167.59,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          167.59,\n          99.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33827988411964427,\n        \"min\": 1.6817,\n        \"max\": 2.1601,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.1601,\n          1.6817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0420\\u043e\\u0437\\u043c\\u0456\\u0440 \\u0432\\u0430\\u0433 (MB)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 169.06923138170353,\n        \"min\": 496.23,\n        \"max\": 735.33,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          735.33,\n          496.23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Інференс на власному прикладі\n",
        "# Використовуємо pipeline для зручності, передаючи навчену модель\n",
        "\n",
        "def test_inference(model, tokenizer, model_name):\n",
        "    print(f\"\\nTesting: {model_name}\")\n",
        "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "    context = \"\"\"\n",
        "    Transformers changed the NLP landscape significantly.\n",
        "    Before transformers, RNNs and LSTMs were the standard.\n",
        "    Google introduced BERT in 2018.\n",
        "    However, transformers can be computationally expensive.\n",
        "    \"\"\"\n",
        "\n",
        "    # Питання, на яке Є відповідь\n",
        "    q1 = \"Who introduced BERT?\"\n",
        "    res1 = qa_pipeline(question=q1, context=context)\n",
        "    print(f\"Q: {q1}\")\n",
        "    print(f\"A: {res1['answer']} (score: {res1['score']:.4f})\")\n",
        "\n",
        "    # Питання, на яке НЕМАЄ відповіді (SQuAD v2 feature)\n",
        "    # Pipeline за замовчуванням намагається знайти відповідь,\n",
        "    # але низький score може свідчити про відсутність відповіді.\n",
        "    q2 = \"When was ChatGPT released?\"\n",
        "    res2 = qa_pipeline(question=q2, context=context)\n",
        "    print(f\"Q: {q2}\")\n",
        "    print(f\"A: {res2['answer']} (score: {res2['score']:.4f})\")"
      ],
      "metadata": {
        "id": "MHBO5hqvXXaz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nІнференс на власних прикладах\")\n",
        "test_inference(trainer_roberta.model, tokenizer_roberta, \"RoBERTa\")\n",
        "test_inference(trainer_deberta.model, tokenizer_deberta, \"DeBERTa\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYGimpFDXZw_",
        "outputId": "c681e1f7-7192-4f3c-f634-dd0aaf8c69f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Інференс на власних прикладах\n",
            "\n",
            "Testing: RoBERTa\n",
            "Q: Who introduced BERT?\n",
            "A: Google introduced BERT in 2018 (score: 0.1267)\n",
            "Q: When was ChatGPT released?\n",
            "A: \n",
            "    (score: 0.0005)\n",
            "\n",
            "Testing: DeBERTa\n",
            "Q: Who introduced BERT?\n",
            "A:  Google (score: 0.4554)\n",
            "Q: When was ChatGPT released?\n",
            "A:  BERT in 2018. (score: 0.0372)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRoVGPxGZjwD"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}